{"env_name": "multi_reward", "algo_name": "mistral_v3_2_1", "train_epoch": 1, "max_episode": 21000, "continue_train": false, "reload_path": "", "reload_run": 1, "reload_episode": 20, "state_dim": 4096, "action_dim": 2, "hidden_dim": 1024, "buffer_capacity": 1000000, "batch_size": 1024, "lr_actor": 0.0003, "lr_critic": 0.0003, "lr_alpha": 0.0003, "alpha": 0.01, "max_grad_norm": 0.5, "replace_tau": 0.005, "gamma": 0.99, "update_time": 10, "random_seed": 2024, "save_interval": 500, "target_entropy_factor": 0.6, "target_entropy_type": "log", "accumulated_step": 1, "policy_model_type": "mistral_instruct_v3", "policy_model_path": "path2model/Mistral-7B-Instruct-v0.3", "policy_model_device": "cuda:0", "reward_model_type": ["beaver_reward", "beaver_cost"], "reward_model_path": ["path2model/beaver-7b-v1.0-reward", "path2model/beaver-7b-v1.0-cost"], "reward_model_device": ["cuda:7", "cuda:7"], "reward_multiplier": [2.0, -1.0], "sft_as_reward_baseline": false, "baseline_multiplier": 1.0, "reward_baseline": 0.0, "postback_reward": 1, "reward_type": "kl_div", "cond_prob": true, "kl_ctl": 0.1, "kl_penalty": "kl", "num_gpus": 8, "num_agents": 7, "share_device": false, "learner_device": "cuda:7", "repeat_cnt": 1, "dataset": "safeRLHF", "dataset_path": "../data/SafeRLHF/train.json", "state_transition": "v0", "reverse_choice": false, "max_new_token": 512, "topk": 40, "topp": 0.95, "temperature": 0.8, "min_tokens_to_keep": 1, "length_penalty": 1.0, "wandb_entity_name": "xx", "wandb_project_name": "xx"}